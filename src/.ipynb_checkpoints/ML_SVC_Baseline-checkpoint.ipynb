{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc1a106e-3cb3-4f64-b938-f7c86968cf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Columns:  40\n",
      "Number of Rows:  246022\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "df = pd.read_csv('data/heart_2022.csv')\n",
    "print (\"Number of Columns: \", df.shape[1])\n",
    "print (\"Number of Rows: \", df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5775ec84-44aa-4de0-a088-ced870b77e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['HadHeartAttack']\n",
    "X = df.loc[:, df.columns != 'HadHeartAttack']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be8ed565-9dd9-4c5f-9f57-d8b2ebd59cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "\n",
    "# Redefine ordinal features and categories\n",
    "ordinal_cats = [\n",
    "    ['Poor', 'Fair', 'Good', 'Very good', 'Excellent'], \n",
    "    ['5 or more years ago', \n",
    "     'Within past 5 years (2 years but less than 5 years ago)', \n",
    "     'Within past 2 years (1 year but less than 2 years ago)', \n",
    "     'Within past year (anytime less than 12 months ago)'], \n",
    "    ['All', '6 or more, but not all', '1 to 5', 'None of them'], \n",
    "    ['Current smoker - now smokes every day', \n",
    "     'Current smoker - now smokes some days', \n",
    "     'Former smoker', \n",
    "     'Never smoked'], \n",
    "    ['Use them every day', 'Use them some days', 'Not at all (right now)', \n",
    "     'Never used e-cigarettes in my entire life'], \n",
    "    ['Age 18 to 24', 'Age 25 to 29', 'Age 30 to 34', 'Age 35 to 39', \n",
    "     'Age 40 to 44', 'Age 45 to 49', 'Age 50 to 54', 'Age 55 to 59', \n",
    "     'Age 60 to 64', 'Age 65 to 69', 'Age 70 to 74', 'Age 75 to 79', \n",
    "     'Age 80 or older']\n",
    "]\n",
    "\n",
    "ordinal_ftrs = ['GeneralHealth', 'LastCheckupTime', 'RemovedTeeth', 'SmokerStatus', 'ECigaretteUsage', 'AgeCategory']\n",
    "minmax_ftrs = ['PhysicalHealthDays', 'MentalHealthDays', 'SleepHours', 'HeightInMeters', 'WeightInKilograms', 'BMI']\n",
    "\n",
    "# Extract binary columns dynamically (only columns with 2 unique values)\n",
    "binary_columns = [\n",
    "    col for col in df.columns\n",
    "    if df[col].nunique() == 2 and df[col].dtype == 'object' and col != 'HadHeartAttack'  # Exclude target variable\n",
    "]\n",
    "\n",
    "# Extract remaining categorical columns for one-hot encoding\n",
    "remaining_onehot_ftrs = [\n",
    "    col for col in df.columns\n",
    "    if col not in binary_columns + ordinal_ftrs + minmax_ftrs + ['HadHeartAttack']\n",
    "]\n",
    "\n",
    "# Updated ColumnTransformer\n",
    "preprocessor_fixed = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('binary', OrdinalEncoder(), binary_columns),  # Encode binary columns as 0/1\n",
    "        ('ord', OrdinalEncoder(categories=ordinal_cats), ordinal_ftrs),  # Ordinal encoding\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'), remaining_onehot_ftrs),  # Remaining categorical\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs)  # Scaling for numerical features\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the final pipeline\n",
    "clf_fixed = Pipeline(steps=[('preprocessor', preprocessor_fixed)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbbb5961-7a67-4f4e-9e01-ed62003af864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state 0\n",
      "Random state 42\n",
      "Random state 84\n",
      "Random state 126\n",
      "Random state 168\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "import numpy as np\n",
    "\n",
    "nr_states = 5\n",
    "\n",
    "# Loop through the different random states\n",
    "for i in range(nr_states):\n",
    "    print('Random state', 42 * i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bd909a5-4f19-49ca-a392-ce7a5a9fe1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state 1\n",
      "    {'C': 0.01, 'gamma': 'scale'}\n",
      "   Train F2: 0.4594017094017094 Validation F2: 0.4355400696864111\n",
      "    {'C': 0.01, 'gamma': 'auto'}\n",
      "   Train F2: 0.4561248126447745 Validation F2: 0.43354943273906\n",
      "    {'C': 0.1, 'gamma': 'scale'}\n",
      "   Train F2: 0.5155529953917051 Validation F2: 0.4905335628227194\n",
      "    {'C': 0.1, 'gamma': 'auto'}\n",
      "   Train F2: 0.5149162239476911 Validation F2: 0.48851978505129456\n",
      "    {'C': 1.0, 'gamma': 'scale'}\n",
      "   Train F2: 0.5462822458270106 Validation F2: 0.4941713127217435\n",
      "    {'C': 1.0, 'gamma': 'auto'}\n",
      "   Train F2: 0.5400919305413687 Validation F2: 0.4992339121552605\n",
      "    {'C': 10.0, 'gamma': 'scale'}\n",
      "   Train F2: 0.6342697609492235 Validation F2: 0.48332019963225636\n",
      "    {'C': 10.0, 'gamma': 'auto'}\n",
      "   Train F2: 0.6055674518201285 Validation F2: 0.4858404780462458\n",
      "    {'C': 100.0, 'gamma': 'scale'}\n",
      "   Train F2: 0.8121390211774242 Validation F2: 0.4213397999393756\n",
      "    {'C': 100.0, 'gamma': 'auto'}\n",
      "   Train F2: 0.7603864734299517 Validation F2: 0.4340277777777778\n",
      "Best model parameters: {'gamma': 'auto', 'C': 1.0}\n",
      "Corresponding validation F2 score: 0.4992339121552605\n",
      "Test F2 score: 0.5171974522292994\n",
      "Random state 2\n",
      "    {'C': 0.01, 'gamma': 'scale'}\n",
      "   Train F2: 0.4505764376833345 Validation F2: 0.4665438919582566\n",
      "    {'C': 0.01, 'gamma': 'auto'}\n",
      "   Train F2: 0.4448853318985809 Validation F2: 0.46198948645369997\n",
      "    {'C': 0.1, 'gamma': 'scale'}\n",
      "   Train F2: 0.5045834015387134 Validation F2: 0.5329576084293065\n",
      "    {'C': 0.1, 'gamma': 'auto'}\n",
      "   Train F2: 0.500693141971785 Validation F2: 0.5351906158357771\n",
      "    {'C': 1.0, 'gamma': 'scale'}\n",
      "   Train F2: 0.5375582944703531 Validation F2: 0.5316770186335403\n",
      "    {'C': 1.0, 'gamma': 'auto'}\n",
      "   Train F2: 0.5325542570951586 Validation F2: 0.5312266733018164\n",
      "    {'C': 10.0, 'gamma': 'scale'}\n",
      "   Train F2: 0.624131341209173 Validation F2: 0.5183557394002068\n",
      "    {'C': 10.0, 'gamma': 'auto'}\n",
      "   Train F2: 0.5954816709292413 Validation F2: 0.5287851889424297\n",
      "    {'C': 100.0, 'gamma': 'scale'}\n",
      "   Train F2: 0.8069251797104384 Validation F2: 0.446619761394922\n",
      "    {'C': 100.0, 'gamma': 'auto'}\n",
      "   Train F2: 0.7578094870806016 Validation F2: 0.47432550043516103\n",
      "Best model parameters: {'gamma': 'auto', 'C': 0.1}\n",
      "Corresponding validation F2 score: 0.5351906158357771\n",
      "Test F2 score: 0.5061609084319884\n",
      "Random state 3\n",
      "    {'C': 0.01, 'gamma': 'scale'}\n",
      "   Train F2: 0.4556525268926324 Validation F2: 0.4514533085961657\n",
      "    {'C': 0.01, 'gamma': 'auto'}\n",
      "   Train F2: 0.4515330030793948 Validation F2: 0.4509283819628647\n",
      "    {'C': 0.1, 'gamma': 'scale'}\n",
      "   Train F2: 0.5204778156996587 Validation F2: 0.4906832298136646\n",
      "    {'C': 0.1, 'gamma': 'auto'}\n",
      "   Train F2: 0.5179652805813484 Validation F2: 0.49150036954915005\n",
      "    {'C': 1.0, 'gamma': 'scale'}\n",
      "   Train F2: 0.5504356568364611 Validation F2: 0.5024228513134404\n",
      "    {'C': 1.0, 'gamma': 'auto'}\n",
      "   Train F2: 0.5459890802183957 Validation F2: 0.4960266598308126\n",
      "    {'C': 10.0, 'gamma': 'scale'}\n",
      "   Train F2: 0.629207664422579 Validation F2: 0.4935339139614674\n",
      "    {'C': 10.0, 'gamma': 'auto'}\n",
      "   Train F2: 0.6038054968287526 Validation F2: 0.4893837389953392\n",
      "    {'C': 100.0, 'gamma': 'scale'}\n",
      "   Train F2: 0.8100530179445351 Validation F2: 0.41718555417185554\n",
      "    {'C': 100.0, 'gamma': 'auto'}\n",
      "   Train F2: 0.7606372644258792 Validation F2: 0.4280618311533888\n",
      "Best model parameters: {'gamma': 'scale', 'C': 1.0}\n",
      "Corresponding validation F2 score: 0.5024228513134404\n",
      "Test F2 score: 0.5031367628607277\n",
      "Random state 4\n",
      "    {'C': 0.01, 'gamma': 'scale'}\n",
      "   Train F2: 0.45355340335561317 Validation F2: 0.4580152671755725\n",
      "    {'C': 0.01, 'gamma': 'auto'}\n",
      "   Train F2: 0.44877422840548387 Validation F2: 0.4544528224984716\n",
      "    {'C': 0.1, 'gamma': 'scale'}\n",
      "   Train F2: 0.5088956563551851 Validation F2: 0.5068392769907182\n",
      "    {'C': 0.1, 'gamma': 'auto'}\n",
      "   Train F2: 0.507033298895335 Validation F2: 0.5053320407174018\n",
      "    {'C': 1.0, 'gamma': 'scale'}\n",
      "   Train F2: 0.5401234567901234 Validation F2: 0.5244399185336049\n",
      "    {'C': 1.0, 'gamma': 'auto'}\n",
      "   Train F2: 0.5342716748563338 Validation F2: 0.5213631739572736\n",
      "    {'C': 10.0, 'gamma': 'scale'}\n",
      "   Train F2: 0.6256481161424127 Validation F2: 0.5095036958817318\n",
      "    {'C': 10.0, 'gamma': 'auto'}\n",
      "   Train F2: 0.5974225484338994 Validation F2: 0.5142632818633865\n",
      "    {'C': 100.0, 'gamma': 'scale'}\n",
      "   Train F2: 0.8054097698829229 Validation F2: 0.4153986609860012\n",
      "    {'C': 100.0, 'gamma': 'auto'}\n",
      "   Train F2: 0.7614873326269146 Validation F2: 0.42857142857142855\n",
      "Best model parameters: {'gamma': 'scale', 'C': 1.0}\n",
      "Corresponding validation F2 score: 0.5244399185336049\n",
      "Test F2 score: 0.5092824887104868\n",
      "Random state 5\n",
      "    {'C': 0.01, 'gamma': 'scale'}\n",
      "   Train F2: 0.44464609800362975 Validation F2: 0.46204952687739076\n",
      "    {'C': 0.01, 'gamma': 'auto'}\n",
      "   Train F2: 0.44184039304209266 Validation F2: 0.4576271186440678\n",
      "    {'C': 0.1, 'gamma': 'scale'}\n",
      "   Train F2: 0.5007262750161394 Validation F2: 0.5237750422399228\n",
      "    {'C': 0.1, 'gamma': 'auto'}\n",
      "   Train F2: 0.501648042447142 Validation F2: 0.5241644626112046\n",
      "    {'C': 1.0, 'gamma': 'scale'}\n",
      "   Train F2: 0.5337125648318555 Validation F2: 0.534504391468005\n",
      "    {'C': 1.0, 'gamma': 'auto'}\n",
      "   Train F2: 0.5301052631578947 Validation F2: 0.5362099419631592\n",
      "    {'C': 10.0, 'gamma': 'scale'}\n",
      "   Train F2: 0.6254893431926924 Validation F2: 0.5005186721991701\n",
      "    {'C': 10.0, 'gamma': 'auto'}\n",
      "   Train F2: 0.6013467439481759 Validation F2: 0.5102817974105103\n",
      "    {'C': 100.0, 'gamma': 'scale'}\n",
      "   Train F2: 0.8080194410692588 Validation F2: 0.4351145038167939\n",
      "    {'C': 100.0, 'gamma': 'auto'}\n",
      "   Train F2: 0.7651676681527427 Validation F2: 0.4570596797671033\n",
      "Best model parameters: {'gamma': 'auto', 'C': 1.0}\n",
      "Corresponding validation F2 score: 0.5362099419631592\n",
      "Test F2 score: 0.5073547743704812\n",
      "Average Test F2 Score: 0.5086264773205966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import ParameterGrid, train_test_split\n",
    "from sklearn.metrics import fbeta_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df is already defined\n",
    "y_target = df['HadHeartAttack']\n",
    "X_features = df.loc[:, df.columns != 'HadHeartAttack']\n",
    "\n",
    "# Reduce the dataset to 20% of its original size\n",
    "X_features, _, y_target, _ = train_test_split(\n",
    "    X_features, y_target, train_size=0.2, stratify=y_target, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "nr_states = 5\n",
    "test_scores = np.zeros(nr_states)\n",
    "final_models = []\n",
    "\n",
    "# Loop through the different random states\n",
    "for i in range(nr_states):\n",
    "    print('Random state', i + 1)\n",
    "\n",
    "    # First split to separate out the training set\n",
    "    X_train, X_other, y_train, y_other = train_test_split(\n",
    "        X_features, y_target, train_size=0.6, stratify=y_target, random_state=42 * i\n",
    "    )\n",
    "\n",
    "    # Second split to separate out the validation and test sets\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_other, y_other, train_size=0.5, stratify=y_other, random_state=42 * i\n",
    "    )\n",
    "\n",
    "    # Preprocess the datasets using the existing pipeline\n",
    "    X_train_prep = clf_fixed.fit_transform(X_train)\n",
    "    X_val_prep = clf_fixed.transform(X_val)\n",
    "    X_test_prep = clf_fixed.transform(X_test)\n",
    "\n",
    "    # Encode the target variable\n",
    "    y_train_encoded = y_train.map({'No': 0, 'Yes': 1})\n",
    "    y_val_encoded = y_val.map({'No': 0, 'Yes': 1})\n",
    "    y_test_encoded = y_test.map({'No': 0, 'Yes': 1})\n",
    "\n",
    "    # Define the parameter grid for SVC\n",
    "    \n",
    "    param_grid = {\n",
    "        'C': [1e-2, 1e-1, 1e0, 1e1, 1e2],  # Regularization parameter\n",
    "        'gamma': ['scale', 'auto']  \n",
    "    }\n",
    "\n",
    "\n",
    "    # Save train and validation scores\n",
    "    train_score = np.zeros(len(ParameterGrid(param_grid)))\n",
    "    val_score = np.zeros(len(ParameterGrid(param_grid)))\n",
    "    models = []\n",
    "\n",
    "    # Loop through all combinations of hyperparameter combos\n",
    "    for p, params in enumerate(ParameterGrid(param_grid)):\n",
    "        print('   ', params)\n",
    "        \n",
    "        try:\n",
    "            # Initialize the SVC classifier\n",
    "            clf_svc = SVC(**params, probability=True, class_weight='balanced')\n",
    "            clf_svc.fit(X_train_prep, y_train_encoded)  # Fit the model\n",
    "            models.append(clf_svc)  # Save it\n",
    "\n",
    "            # Calculate train and validation F2 scores\n",
    "            y_train_pred = clf_svc.predict(X_train_prep)\n",
    "            train_score[p] = fbeta_score(\n",
    "                y_train_encoded, y_train_pred, beta=2, average='binary'\n",
    "            )  # Use F2 score\n",
    "            y_val_pred = clf_svc.predict(X_val_prep)\n",
    "            val_score[p] = fbeta_score(\n",
    "                y_val_encoded, y_val_pred, beta=2, average='binary'\n",
    "            )  # Use F2 score\n",
    "            print('   Train F2:', train_score[p], 'Validation F2:', val_score[p])\n",
    "        \n",
    "        except ValueError as e:\n",
    "            print(f\"Skipped params due to error: {params}\\nError: {e}\")\n",
    "            train_score[p] = -1  # Mark invalid combinations\n",
    "            val_score[p] = -1\n",
    "\n",
    "    # Print out model parameters that maximize validation F2 score\n",
    "    best_idx = np.argmax(val_score)\n",
    "    print('Best model parameters:', ParameterGrid(param_grid)[best_idx])\n",
    "    print('Corresponding validation F2 score:', np.max(val_score))\n",
    "\n",
    "    # Collect and save the best model\n",
    "    final_models.append(models[best_idx])\n",
    "\n",
    "    # Calculate and save the test F2 score\n",
    "    y_test_pred = final_models[-1].predict(X_test_prep)\n",
    "    test_scores[i] = fbeta_score(\n",
    "        y_test_encoded, y_test_pred, beta=2, average='binary'\n",
    "    )  # Use F2 score\n",
    "    print('Test F2 score:', test_scores[i])\n",
    "\n",
    "# Print the average test F2 score across all random states\n",
    "print('Average Test F2 Score:', np.mean(test_scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f6f1c3d-2b7f-4c3a-bcb1-bc6c1a32b435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classifier Mean: 0.5086264773205966\n",
      "Support Vector Classifier Standard Deviation: 0.004727053733944148\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example array\n",
    "svc_array = np.array([0.5171974522292994, 0.5061609084319884, 0.5031367628607277, 0.5092824887104868, 0.5073547743704812])\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean = np.mean(svc_array)\n",
    "std_dev = np.std(svc_array)\n",
    "\n",
    "print(f\"Support Vector Classifier Mean: {mean}\")\n",
    "print(f\"Support Vector Classifier Standard Deviation: {std_dev}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8e78249-a4a8-42e4-81b2-47cd433c6004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.054608937412101356, 1.0, 0.22409444826228805)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given confusion matrix values\n",
    "false_positives = 232587/246022\n",
    "false_negatives = 0\n",
    "true_positives = 13435/246022\n",
    "\n",
    "# Calculate precision and recall for the majority class baseline\n",
    "# Baseline assumes predicting all as the majority class (negative class)\n",
    "precision_baseline = true_positives / (true_positives + false_positives)\n",
    "recall_baseline = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "# Calculate the F2 score\n",
    "beta = 2\n",
    "f2_baseline = (1 + beta**2) * (precision_baseline * recall_baseline) / (\n",
    "    beta**2 * precision_baseline + recall_baseline\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "precision_baseline, recall_baseline, f2_baseline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ad7a4d-d440-4bd1-9b1b-f51aaf3f86f6",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
